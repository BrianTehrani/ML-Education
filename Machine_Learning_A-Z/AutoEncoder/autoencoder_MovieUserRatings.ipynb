{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "\n",
    "*Project Description*\n",
    "- Develop a model to predict a users next movie rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ae096e-7ee6-4538-9417-8055a758bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Set up device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below dataset is used to train autoencoder on 1 million user ratings.\n",
    "The current model is tested off a dataset containing 100k user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1985733e-4106-4b28-863d-81285f2ea8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't be using this dataset. \n",
    "# movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Testing and Training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c9acdd-eee1-470d-a1d5-79bbd585b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t', header = None)\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t', header = None)\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f6316d2-ed47-4ceb-87df-251e2c30e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Getting the number of users and movies\n",
    "\n",
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))\n",
    "\n",
    "mins = int(min(min(training_set[:, 1], ), min(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d83533-0526-4a14-88bb-3a11aac17d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Converting the data into an array with users in lines and movies in columns\n",
    "\n",
    "def convertData(data:np.array):\n",
    "    \"\"\" \n",
    "        Convert training data into 2D matrix where row indicies equal users and\n",
    "        columns equal movie id. Cell reffers to user rating.\n",
    "        \n",
    "        Fill 0 for user who did not rate a movie.\n",
    "        \n",
    "        Information from training data:\n",
    "        Column 1: User -> min user = 1, max user = 943\n",
    "        Column 2: Movie -> min id = 1, max id = 1682\n",
    "        Column 3: Rating\n",
    "        Column 4: Timestamp\n",
    "    \n",
    "    \"\"\"\n",
    "    convert_data = []\n",
    "    for user in range(1, nb_users + 1):\n",
    "        zeros = [0] * (nb_movies + 1)\n",
    "        single_user_reviews = data[data[:, 0] == user]\n",
    "        for rating in single_user_reviews:\n",
    "            zeros[rating[1]] = rating[2]\n",
    "        zeros.pop(0) #no movie id that = 0\n",
    "        convert_data.append(zeros)\n",
    "    \n",
    "    return convert_data\n",
    "\n",
    "training_set = convertData(training_set)\n",
    "test_set = convertData(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a59a5473-3db2-42cc-991e-c36d36d675b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btehrani\\AppData\\Local\\Temp\\ipykernel_55164\\2225292254.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  training_set = torch.tensor(training_set, dtype=torch.float).to(device)\n",
      "C:\\Users\\btehrani\\AppData\\Local\\Temp\\ipykernel_55164\\2225292254.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_set = torch.tensor(test_set, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "#%% Converting the data into Torch tensors\n",
    "\n",
    "training_set = torch.tensor(training_set, dtype=torch.float).to(device)\n",
    "test_set = torch.tensor(test_set, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Develop Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14997142-929a-4e55-9590-cdc555a1e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda\n"
     ]
    }
   ],
   "source": [
    "#%% Creating the architecture of the Neural Network\n",
    "\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(nb_movies, 20),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.Linear(20, nb_movies)\n",
    "        )\n",
    "        #self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):   \n",
    "       return self.layers(x)\n",
    "   \n",
    "sae = SAE().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay= 0.5)   \n",
    "\n",
    "print(f\"Model is on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4118f93d-3867-4aa4-85d5-fe1a9b30d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 2.932022894989428\n",
      "epoch: 2 loss: 2.8846614639011885\n",
      "epoch: 3 loss: 2.874855224822831\n",
      "epoch: 4 loss: 2.8689575678661106\n",
      "epoch: 5 loss: 2.86552831826725\n",
      "epoch: 6 loss: 2.8615621762483507\n",
      "epoch: 7 loss: 2.859476122865934\n",
      "epoch: 8 loss: 2.857108151439103\n",
      "epoch: 9 loss: 2.8552896999774857\n",
      "epoch: 10 loss: 2.8538914339525774\n",
      "epoch: 11 loss: 2.8520950116738675\n",
      "epoch: 12 loss: 2.850581408586422\n",
      "epoch: 13 loss: 2.8491413325258934\n",
      "epoch: 14 loss: 2.8477188911910347\n",
      "epoch: 15 loss: 2.846965920623003\n",
      "epoch: 16 loss: 2.845937310928483\n",
      "epoch: 17 loss: 2.8450520465930422\n",
      "epoch: 18 loss: 2.8430517674175775\n",
      "epoch: 19 loss: 2.8411078441514634\n",
      "epoch: 20 loss: 2.8396996253688926\n",
      "epoch: 21 loss: 2.8377880306557453\n",
      "epoch: 22 loss: 2.8357254228698006\n",
      "epoch: 23 loss: 2.8341613461699446\n",
      "epoch: 24 loss: 2.8308008912570686\n",
      "epoch: 25 loss: 2.8112551747333767\n",
      "epoch: 26 loss: 2.795532916959039\n",
      "epoch: 27 loss: 2.7951498645220285\n",
      "epoch: 28 loss: 2.794929168894925\n",
      "epoch: 29 loss: 2.7949151606574487\n",
      "epoch: 30 loss: 2.794870110342373\n",
      "epoch: 31 loss: 2.794875281018701\n",
      "epoch: 32 loss: 2.794852071888467\n",
      "epoch: 33 loss: 2.7948586407057485\n",
      "epoch: 34 loss: 2.7948431619952494\n",
      "epoch: 35 loss: 2.7948493593945636\n",
      "epoch: 36 loss: 2.7948377867683307\n",
      "epoch: 37 loss: 2.7948434058531606\n",
      "epoch: 38 loss: 2.794834184319064\n",
      "epoch: 39 loss: 2.794839252284191\n",
      "epoch: 40 loss: 2.7948315995886035\n",
      "epoch: 41 loss: 2.7948361840898426\n",
      "epoch: 42 loss: 2.7948296485560338\n",
      "epoch: 43 loss: 2.7948338271317623\n",
      "epoch: 44 loss: 2.794828128921046\n",
      "epoch: 45 loss: 2.794831955761675\n",
      "epoch: 46 loss: 2.7948269073996603\n",
      "epoch: 47 loss: 2.794830434061148\n",
      "epoch: 48 loss: 2.7948259120795993\n",
      "epoch: 49 loss: 2.794829176844721\n",
      "epoch: 50 loss: 2.7948250768931957\n",
      "epoch: 51 loss: 2.7948281151818173\n",
      "epoch: 52 loss: 2.7948243678225837\n",
      "epoch: 53 loss: 2.794827210740639\n",
      "epoch: 54 loss: 2.794823764082333\n",
      "epoch: 55 loss: 2.794826429038093\n",
      "epoch: 56 loss: 2.794823238475226\n",
      "epoch: 57 loss: 2.794825749526022\n",
      "epoch: 58 loss: 2.794822778571752\n",
      "epoch: 59 loss: 2.794825149617524\n",
      "epoch: 60 loss: 2.7948223743015816\n",
      "epoch: 61 loss: 2.794824619075097\n",
      "epoch: 62 loss: 2.7948220127179617\n",
      "epoch: 63 loss: 2.794824146483566\n",
      "epoch: 64 loss: 2.7948216925787945\n",
      "epoch: 65 loss: 2.7948237220895105\n",
      "epoch: 66 loss: 2.794821403746051\n",
      "epoch: 67 loss: 2.7948233387066543\n",
      "epoch: 68 loss: 2.7948211410664983\n",
      "epoch: 69 loss: 2.794822991865224\n",
      "epoch: 70 loss: 2.7948209046781276\n",
      "epoch: 71 loss: 2.794822672525365\n",
      "epoch: 72 loss: 2.7948206869039125\n",
      "epoch: 73 loss: 2.7948223847741573\n",
      "epoch: 74 loss: 2.794820489220577\n",
      "epoch: 75 loss: 2.794822120032997\n",
      "epoch: 76 loss: 2.7948203039323896\n",
      "epoch: 77 loss: 2.7948218737881727\n",
      "epoch: 78 loss: 2.7948201376867052\n",
      "epoch: 79 loss: 2.7948216480002874\n",
      "epoch: 80 loss: 2.7948199824836752\n",
      "epoch: 81 loss: 2.7948214380782677\n",
      "epoch: 82 loss: 2.794819837851805\n",
      "epoch: 83 loss: 2.7948212440018123\n",
      "epoch: 84 loss: 2.79481970286093\n",
      "epoch: 85 loss: 2.794821063042265\n",
      "epoch: 86 loss: 2.7948195778171754\n",
      "epoch: 87 loss: 2.794820892517084\n",
      "epoch: 88 loss: 2.7948194596422997\n",
      "epoch: 89 loss: 2.794820734544281\n",
      "epoch: 90 loss: 2.794819350968799\n",
      "epoch: 91 loss: 2.7948205859866944\n",
      "epoch: 92 loss: 2.7948192496628583\n",
      "epoch: 93 loss: 2.7948204479492516\n",
      "epoch: 94 loss: 2.794819152527558\n",
      "epoch: 95 loss: 2.794820316444342\n",
      "epoch: 96 loss: 2.7948190645399205\n",
      "epoch: 97 loss: 2.7948201923040745\n",
      "epoch: 98 loss: 2.7948189753721997\n",
      "epoch: 99 loss: 2.7948200747333276\n",
      "epoch: 100 loss: 2.79481889547116\n",
      "epoch: 101 loss: 2.794819964393554\n",
      "epoch: 102 loss: 2.794818816899071\n",
      "epoch: 103 loss: 2.7948198598521206\n",
      "epoch: 104 loss: 2.7948187470903747\n",
      "epoch: 105 loss: 2.794819761071067\n",
      "epoch: 106 loss: 2.7948186782720565\n",
      "epoch: 107 loss: 2.7948196665106737\n",
      "epoch: 108 loss: 2.794818610736529\n",
      "epoch: 109 loss: 2.794819578812979\n",
      "epoch: 110 loss: 2.7948185504728604\n",
      "epoch: 111 loss: 2.794819492484384\n",
      "epoch: 112 loss: 2.7948184911983867\n",
      "epoch: 113 loss: 2.794819410459879\n",
      "epoch: 114 loss: 2.7948184333048323\n",
      "epoch: 115 loss: 2.7948193313221306\n",
      "epoch: 116 loss: 2.7948183798262694\n",
      "epoch: 117 loss: 2.7948192574842916\n",
      "epoch: 118 loss: 2.794818326889708\n",
      "epoch: 119 loss: 2.7948191856925177\n",
      "epoch: 120 loss: 2.7948182786497147\n",
      "epoch: 121 loss: 2.7948191187976743\n",
      "epoch: 122 loss: 2.7948182328804814\n",
      "epoch: 123 loss: 2.7948190542137965\n",
      "epoch: 124 loss: 2.7948181859860615\n",
      "epoch: 125 loss: 2.7948189930231813\n",
      "epoch: 126 loss: 2.7948181422728555\n",
      "epoch: 127 loss: 2.7948189323254806\n",
      "epoch: 128 loss: 2.7948181014507507\n",
      "epoch: 129 loss: 2.7948188757489114\n",
      "epoch: 130 loss: 2.794818060307282\n",
      "epoch: 131 loss: 2.794818821023367\n",
      "epoch: 132 loss: 2.7948180230754134\n",
      "epoch: 133 loss: 2.794818767945712\n",
      "epoch: 134 loss: 2.794817985762244\n",
      "epoch: 135 loss: 2.794818715760476\n",
      "epoch: 136 loss: 2.7948179508662636\n",
      "epoch: 137 loss: 2.7948186677219384\n",
      "epoch: 138 loss: 2.7948179150759\n",
      "epoch: 139 loss: 2.794818619751162\n",
      "epoch: 140 loss: 2.794817881346588\n",
      "epoch: 141 loss: 2.79481857314539\n",
      "epoch: 142 loss: 2.794817849917688\n",
      "epoch: 143 loss: 2.7948185287786327\n",
      "epoch: 144 loss: 2.7948178196268794\n",
      "epoch: 145 loss: 2.794818487148664\n",
      "epoch: 146 loss: 2.7948177903977944\n",
      "epoch: 147 loss: 2.79481844573079\n",
      "epoch: 148 loss: 2.794817762814531\n",
      "epoch: 149 loss: 2.7948184065258697\n",
      "epoch: 150 loss: 2.7948177348965224\n",
      "epoch: 151 loss: 2.794818367789804\n",
      "epoch: 152 loss: 2.7948177082348757\n",
      "epoch: 153 loss: 2.794818330353616\n",
      "epoch: 154 loss: 2.794817682589229\n",
      "epoch: 155 loss: 2.7948182937228077\n",
      "epoch: 156 loss: 2.7948176587910742\n",
      "epoch: 157 loss: 2.7948182596079176\n",
      "epoch: 158 loss: 2.794817634075525\n",
      "epoch: 159 loss: 2.794818225574524\n",
      "epoch: 160 loss: 2.7948176095277986\n",
      "epoch: 161 loss: 2.794818192452391\n",
      "epoch: 162 loss: 2.7948175876582213\n",
      "epoch: 163 loss: 2.794818161530488\n",
      "epoch: 164 loss: 2.7948175658579633\n",
      "epoch: 165 loss: 2.79481813108989\n",
      "epoch: 166 loss: 2.794817543593894\n",
      "epoch: 167 loss: 2.794818100880645\n",
      "epoch: 168 loss: 2.7948175234576795\n",
      "epoch: 169 loss: 2.79481807155368\n",
      "epoch: 170 loss: 2.7948175028624296\n",
      "epoch: 171 loss: 2.794818042704732\n",
      "epoch: 172 loss: 2.7948174845157743\n",
      "epoch: 173 loss: 2.7948180159949065\n",
      "epoch: 174 loss: 2.7948174644582733\n",
      "epoch: 175 loss: 2.7948179884048723\n",
      "epoch: 176 loss: 2.7948174463797253\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_2, target)\n\u001b[0;32m     42\u001b[0m mean_corrector \u001b[38;5;241m=\u001b[39m nb_movies\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum(target\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m mean_corrector)\n\u001b[0;32m     46\u001b[0m s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\btehrani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\btehrani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    \n",
    "    train_loss = 0\n",
    "\n",
    "    # Count number of users that rated 1 movie\n",
    "    # Do not count users who did not rate any movie for memory optimization\n",
    "    s = 0. # Will use to compute RMS error\n",
    "\n",
    "    for id_user in range(nb_users):\n",
    "        input_x = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input_x.clone()\n",
    "\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            \n",
    "            output = torch.sigmoid(sae(input_x))\n",
    "            #output = sae(input_x)\n",
    "\n",
    "            # Optimize code to not compute gradients on target, only input tensor\n",
    "            target.require_grad = False\n",
    "           \n",
    "            \"\"\" \n",
    "                Below is necessary for optimization and model performance.\n",
    "\n",
    "                If a user did not rate a movie and the model predicts their rating to be high,\n",
    "                the model will calulate this RMS error and will adjust inappropriately:\n",
    "\n",
    "                ex/ User did not rate movie = 0 \n",
    "                    Model predicts = 3\n",
    "\n",
    "                    This result will carry over to loss and assume a loss of 3. \n",
    "                    Model loss will theerefore have a difficult time decreasing.\n",
    "            \"\"\"\n",
    "            # output[target == 0] = 0\n",
    "            output_2 = torch.where(target == 0, torch.tensor(0.), output)\n",
    "\n",
    "            # output_2 = output.clone()\n",
    "            # output_2[target == 0] = 0\n",
    "\n",
    "            loss = criterion(output_2, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            \n",
    "            loss.backward()\n",
    "            train_loss = train_loss + np.sqrt(loss.item() * mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "\n",
    "    #if epoch % 10 == 0:\n",
    "    print('epoch: ' + str(epoch) + ' loss: '+ str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b02f3f-bece-4555-8717-e1c46689c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9482630600945305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%% Testing the SAE\n",
    "\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input_x = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input_x)\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "        s += 1.\n",
    "\n",
    "print('test loss: '+ str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model takes a while to train on most systems.\n",
    "Save / Load model state after training in case errors occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sae, '/model_sae.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
